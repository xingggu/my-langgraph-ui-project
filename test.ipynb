{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# Please install OpenAI SDK first: `pip3 install openai`\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– LLM Response:\n",
      " Hello! ğŸ˜Š I'm DeepSeek Chat, your AI assistant created by DeepSeek. I'm here to help answer your questions, provide information, and assist with anything from learning new topics to brainstorming ideas. Feel free to ask me anythingâ€”I'm happy to help! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# âœ… è¯»å– .env æ–‡ä»¶\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… ä»ç¯å¢ƒå˜é‡ä¸­è·å– DeepSeek çš„ API Key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEY not found in .env\")\n",
    "\n",
    "# âœ… æ„å»º LangChain çš„ ChatOpenAI å¯¹è±¡ï¼ŒæŒ‡å®š DeepSeek åœ°å€\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    base_url=\"https://api.deepseek.com/v1\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# âœ… æ‰§è¡Œä¸€æ¬¡å¯¹è¯è°ƒç”¨\n",
    "response = llm.invoke(\"Hello, who are you?\")\n",
    "\n",
    "# âœ… è¾“å‡ºç»“æœ\n",
    "print(\"ğŸ¤– LLM Response:\\n\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38acbcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPENAI_API_KEY loaded: True\n",
      ">>> .env key: sk-3c0ac93bfc28454896dd13cc6cd3bba1\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… OPENAI_API_KEY loaded:\", os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "print(\">>> .env key:\", os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef41c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Current Working Directory: d:\\LangChain\\LangGraph\\my-langgraph-ui-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸ“ Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6286067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> sys env: sk-3c0ac93bfc28454896dd13cc6cd3bba1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\">>> sys env:\", os.environ.get(\"OPENAI_API_KEY\"))  # ç³»ç»Ÿç¯å¢ƒå˜é‡ä¼˜å…ˆ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
